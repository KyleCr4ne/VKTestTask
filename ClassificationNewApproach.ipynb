{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Другой подход"
      ],
      "metadata": {
        "id": "eidmSw59I0ye"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f8keiQJcIwK6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/intern_task_train.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/intern_task_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "def NDCG_atK_score(test_Data, pred_Data, k, logits=False):\n",
        "  query_ids = test_Data['query_id'].unique()\n",
        "  y_true_sessions = [[int(rank) for rank in test_Data[test_Data['query_id'] == id]['rank']] for id in query_ids]\n",
        "  y_pred_sessions = [[int(rank) for rank in pred_Data[pred_Data['query_id'] == id]['rank']] for id in query_ids]\n",
        "  if logits:\n",
        "    print(y_true_sessions)\n",
        "    print(y_pred_sessions)\n",
        "  ndcg_scores = [ndcg_score([y_true_sessions[i]], [y_pred_sessions[i]], k=5) for i in range(len(y_true_sessions)) if len(y_true_sessions[i]) > 1]\n",
        "  return np.mean(ndcg_scores)"
      ],
      "metadata": {
        "id": "eN-fbePrJC7v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "QXbLKVI_SOgB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6c0ee58-e704-4435-db09-0f4e4eb601cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed catboost-1.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['clf0'] = (df_train['rank'] > 0).astype(int)\n",
        "df_train['clf1'] = (df_train['rank'] > 1).astype(int)\n",
        "df_train['clf2'] = (df_train['rank'] > 2).astype(int)\n",
        "df_train['clf3'] = (df_train['rank'] > 3).astype(int)"
      ],
      "metadata": {
        "id": "GdBOpMjEMSsg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features = ['feature_95', 'feature_96', 'feature_97', 'feature_98', 'feature_99', 'feature_1', 'feature_3', 'feature_28']\n",
        "for feature in cat_features:\n",
        "  df_train[feature] = df_train[feature].astype(int)\n",
        "  df_test[feature] = df_test[feature].astype(int)"
      ],
      "metadata": {
        "id": "GYk2QvbdMdK4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "class Ensemble():\n",
        "  def __init__(self):\n",
        "    self.cat_features = ['feature_95', 'feature_96', 'feature_97', 'feature_98', 'feature_99', 'feature_1', 'feature_3', 'feature_28']\n",
        "    self.clf0 = CatBoostClassifier(cat_features=self.cat_features, task_type=\"GPU\")\n",
        "    self.clf1 = CatBoostClassifier(cat_features=self.cat_features, task_type=\"GPU\")\n",
        "    self.clf2 = CatBoostClassifier(cat_features=self.cat_features, task_type=\"GPU\")\n",
        "    self.clf3 = CatBoostClassifier(cat_features=self.cat_features, task_type=\"GPU\")\n",
        "\n",
        "  def fit(self, X, Y):\n",
        "    self.clf0.fit(X, Y['clf0'])\n",
        "    self.clf1.fit(X, Y['clf1'])\n",
        "    self.clf2.fit(X, Y['clf2'])\n",
        "    self.clf3.fit(X, Y['clf3'])\n",
        "\n",
        "  def predict(self, X):\n",
        "    self.y_pred_0 = self.clf0.predict_proba(X)\n",
        "    self.y_pred_1 = self.clf1.predict_proba(X)\n",
        "    self.y_pred_2 = self.clf2.predict_proba(X)\n",
        "    self.y_pred_3 = self.clf3.predict_proba(X)\n",
        "\n",
        "    return self.transform()\n",
        "\n",
        "  def transform(self):\n",
        "    output = []\n",
        "    for i in range(len(self.y_pred_0)):\n",
        "      f0 = self.y_pred_0[i][0]\n",
        "      f1 = self.y_pred_0[i][1] - self.y_pred_1[i][1]\n",
        "      f2 = self.y_pred_1[i][1] - self.y_pred_2[i][1]\n",
        "      f3 = self.y_pred_2[i][1] - self.y_pred_3[i][1]\n",
        "      f4 = self.y_pred_3[i][1]\n",
        "      f = np.array([f0, f1, f2, f3, f4])\n",
        "      output.append(np.argmax(f))\n",
        "    return np.array(output)"
      ],
      "metadata": {
        "id": "aTK-xZ9lk-aQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = Ensemble()\n",
        "clf.fit(df_train.drop(columns=['rank', 'query_id', 'clf0', 'clf1', 'clf2', 'clf3']), df_train)"
      ],
      "metadata": {
        "id": "Yg9Pd1GXMqZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = clf.predict(df_test.drop(columns=['query_id', 'rank']))\n",
        "df_tmp = df_test.copy()\n",
        "df_tmp['rank'] = outputs\n",
        "print(\"NDCG@5 score : \", NDCG_atK_score(df_test, df_tmp, k=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn03Qse2NDj4",
        "outputId": "0457b5c4-9957-4ad1-d2c2-6857eea77f14"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NDCG@5 score :  0.4516808924180702\n"
          ]
        }
      ]
    }
  ]
}