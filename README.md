# VK Test Task
*Тестовое задания для ВКонтакте на позицию инженера машинного обучения*

## Задача

- Подготовить и проверить датасет
- Выбрать модель и обучить ее ранжировать документы по их признакам внутри поисковой сессии
- Посчитать метрику NDCG@5

## Датасет

Файл intern_task.csv

Датасет содержит записи со следующими параметрами:

- **query_id** - идентификатор поисковой сессии
- **feature_i** ($i \in [0, 143]$) - вектор фичей документа
- **rank** - ранг документа (Целочисленные значения от 0 до 4)

## Анализ датасета, предобработка данных

Проанализируем данные датасета, разделим данные на тренировочные и тестовые с учетом особенностей структуры 

[Ноутбук](./DataPreprocessingAndFeatureExtraction.ipynb)

## Модель мультиклассовой классификации

Попробуем посмотреть на данную задачу ранжирования с точки зрения мультиклассовой классификации. Так как за ранжирование документов отвечает rank, принимающий 5 значений, то попробуем спрогнозировать его значение по вектору признаков. Следовательно, в данном предположении мы не учитываем структуру датасета, а именно группировку документов по поисковой сессии. 

[Ноутбук](./MultiClassApproach.ipynb)

В результате, получили такие результаты:

- Логистическая регрессия справилась плохо
- Классификатор на градиентом бустинге с использованием фреймворка CatBoost справился значительно лучше, но все также результаты нельзя назвать хорошими

## Новый подход к созданию модели

Проблема предыдущих подходов с использованием мультиклассовой классификации заключается в том, что мы не используем того факта, что ранги имеют упорядоченную структуру (условно, ранг 3 лучше ранга 2, но хуже ранга 4). В новом подходе попробуем использовать этот факт.

Для этого, будем использовать четыре классификатора, каждый из которых не просто отделяет один класс от всех остальных как в подходе OvR, а делит шкалу рангов на интервалы. Таким образом, первый классификатор **clf0 будет определять метка ранга больше 0 или нет**. **clf1 будет опредялять метка ранга больше 1 или нет** и так далее. Таким образом модель уже начинает понимать о структуре меток и метки уже не воспринимаются как раноправные классы.

Как же теперь определить на основе этих классифкаторов какую метку ранга присвоить тому или иному объекту?

Пусть каждый из классификаторов будет прогнозить вероятность. И тогда для каждого сэмпла можно будет составить вероятность иметь метку 0, 1, 2, 3, 4:

- pr(rank=0) = 1 - pr(clf0)
- pr(rank=1) = pr(clf0) - pf(clf1)
- pr(rank=2) = pr(clf1) - pf(clf2)
- pr(rank=3) = pr(clf2) - pf(clf3)
- pr(rank=4) = pr(clf3)

Действительно, ведь если clf0 выдает вероятность метки ранга быть больше 0,то вероятность иметь метку 0 равна единице минус эта вероятность. Вероятность метки ранга иметь метку 1 равна вероятность метки быть больше нуля минус вероятность метки быть больше 1 (как раз получаем вероятность ранга 1). И так далее.

Для этого был реализован реализован класс Ensemble (по аналогии, как алгоритм, результаты которого зависят от работы нескольких других алгоритмов, пусть и в данным случае более сильных).

Ознакомится с этой идеей с точки зрения реализации можно в [ноутбуке](./ClassificationNewApproach.ipynb).

### Вывод:

Новый подход дейсвительно показал улучшение показателей по метрике по сравнению с мультиклассовой классификацией, хоть и результаты не получили ярко выраженный прирост. Связано это с тем, что базовый классификаторы в классе (а именно clf0, clf1) не так хорошо справляются со своей задачей, что довольно важно в этом подходе, так как общее распределение вероятностей строится на всех классификаторах. Вероятно, требуется лучше подготовить данные, а для этого необходимо понимать некоторое устройство признаков (то есть знать, что они означают) и конкретную задачу, которую мы решаем. Так или иначе метод оказался дейсвительно лучше, подтвердив важность не просто спрогнозировать метки рангов, как равноправные классы, а учесть контекст конкретной поисковой сессии.


## Использование специализированной модели 

В заключение попробуем использовать специально разработанную модель для ранжирования CatBoostRanker. [Ноутбук](./CatBoostRankerTest.ipynb). Как ни странно, модель показала себя лучше любого из подходов. 


Также хочется отметить несколько общих соображений:

- Результаты любой модели можно улучшить, если более тщательно предобработать данные и/или настроить гиперпараметры модели.
- Модель, которая учитывает порядок меток ранга, справляется лучше, чем просто модель мультиклассовой классификации

